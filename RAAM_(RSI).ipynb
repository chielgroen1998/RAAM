{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chielgroen1998/RAAM/blob/main/RAAM_(RSI).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vd-BcFoNfsy5",
        "outputId": "4c0ccd41-12d2-4dbb-d0d2-0e7db7357d9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.11/dist-packages (0.2.65)\n",
            "Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.0.2)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.32.3)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.11/dist-packages (from yfinance) (0.0.12)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from yfinance) (4.3.8)\n",
            "Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2025.2)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.4.6)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.11/dist-packages (from yfinance) (3.18.2)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.11/dist-packages (from yfinance) (4.13.4)\n",
            "Requirement already satisfied: curl_cffi>=0.7 in /usr/local/lib/python3.11/dist-packages (from yfinance) (0.12.0)\n",
            "Requirement already satisfied: protobuf>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from yfinance) (5.29.5)\n",
            "Requirement already satisfied: websockets>=13.0 in /usr/local/lib/python3.11/dist-packages (from yfinance) (15.0.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (4.14.1)\n",
            "Requirement already satisfied: cffi>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from curl_cffi>=0.7->yfinance) (1.17.1)\n",
            "Requirement already satisfied: certifi>=2024.2.2 in /usr/local/lib/python3.11/dist-packages (from curl_cffi>=0.7->yfinance) (2025.7.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.0->yfinance) (2.9.0.post0)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.0->yfinance) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (2.5.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12.0->curl_cffi>=0.7->yfinance) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->yfinance) (1.17.0)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (5.24.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly) (8.5.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from plotly) (25.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install yfinance\n",
        "!pip install plotly\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gu40w1ZjwU28",
        "outputId": "eb0696f9-fb6a-4cdf-c345-70f134c9685f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting download of stock data...\n",
            "\n",
            "Downloading data for AAPL...\n",
            "AAPL: Got 814 prices from 2010-01-01 00:00:00-05:00 to 2025-08-01 00:00:00-04:00\n",
            "Successfully processed AAPL (full history)\n",
            "\n",
            "Downloading data for MSFT...\n",
            "MSFT: Got 814 prices from 2010-01-01 00:00:00-05:00 to 2025-08-01 00:00:00-04:00\n",
            "Successfully processed MSFT (full history)\n",
            "\n",
            "Downloading data for GOOG...\n",
            "GOOG: Got 814 prices from 2010-01-01 00:00:00-05:00 to 2025-08-01 00:00:00-04:00\n",
            "Successfully processed GOOG (full history)\n",
            "\n",
            "Downloading data for AMZN...\n",
            "AMZN: Got 814 prices from 2010-01-01 00:00:00-05:00 to 2025-08-01 00:00:00-04:00\n",
            "Successfully processed AMZN (full history)\n",
            "\n",
            "Downloading data for NVDA...\n",
            "NVDA: Got 814 prices from 2010-01-01 00:00:00-05:00 to 2025-08-01 00:00:00-04:00\n",
            "Successfully processed NVDA (full history)\n",
            "\n",
            "Downloading data for META...\n",
            "META: Got 691 prices from 2012-05-14 00:00:00-04:00 to 2025-08-04 00:00:00-04:00\n",
            "Successfully processed META (full history)\n",
            "\n",
            "Downloading data for TSLA...\n",
            "TSLA: Got 789 prices from 2010-06-28 00:00:00-04:00 to 2025-08-04 00:00:00-04:00\n",
            "Successfully processed TSLA (full history)\n",
            "\n",
            "Downloading data for PEP...\n",
            "PEP: Got 814 prices from 2010-01-01 00:00:00-05:00 to 2025-08-01 00:00:00-04:00\n",
            "Successfully processed PEP (full history)\n",
            "\n",
            "Downloading data for AVGO...\n",
            "AVGO: Got 814 prices from 2010-01-01 00:00:00-05:00 to 2025-08-01 00:00:00-04:00\n",
            "Successfully processed AVGO (full history)\n",
            "\n",
            "Downloading data for COST...\n",
            "COST: Got 814 prices from 2010-01-01 00:00:00-05:00 to 2025-08-01 00:00:00-04:00\n",
            "Successfully processed COST (full history)\n",
            "\n",
            "Downloading data for CSCO...\n",
            "CSCO: Got 814 prices from 2010-01-01 00:00:00-05:00 to 2025-08-01 00:00:00-04:00\n",
            "Successfully processed CSCO (full history)\n",
            "\n",
            "Downloading data for ADBE...\n",
            "ADBE: Got 814 prices from 2010-01-01 00:00:00-05:00 to 2025-08-01 00:00:00-04:00\n",
            "Successfully processed ADBE (full history)\n",
            "\n",
            "Downloading data for NFLX...\n",
            "NFLX: Got 814 prices from 2010-01-01 00:00:00-05:00 to 2025-08-01 00:00:00-04:00\n",
            "Successfully processed NFLX (full history)\n",
            "\n",
            "Downloading data for TMUS...\n",
            "TMUS: Got 814 prices from 2010-01-01 00:00:00-05:00 to 2025-08-01 00:00:00-04:00\n",
            "Successfully processed TMUS (full history)\n",
            "\n",
            "Downloading data for TXN...\n",
            "TXN: Got 814 prices from 2010-01-01 00:00:00-05:00 to 2025-08-01 00:00:00-04:00\n",
            "Successfully processed TXN (full history)\n",
            "\n",
            "Downloading data for CMCSA...\n",
            "CMCSA: Got 814 prices from 2010-01-01 00:00:00-05:00 to 2025-08-01 00:00:00-04:00\n",
            "Successfully processed CMCSA (full history)\n",
            "\n",
            "Downloading data for QCOM...\n",
            "QCOM: Got 814 prices from 2010-01-01 00:00:00-05:00 to 2025-08-01 00:00:00-04:00\n",
            "Successfully processed QCOM (full history)\n",
            "\n",
            "Downloading data for INTC...\n",
            "INTC: Got 814 prices from 2010-01-01 00:00:00-05:00 to 2025-08-01 00:00:00-04:00\n",
            "Successfully processed INTC (full history)\n",
            "\n",
            "Downloading data for HON...\n",
            "HON: Got 814 prices from 2010-01-01 00:00:00-05:00 to 2025-08-01 00:00:00-04:00\n",
            "Successfully processed HON (full history)\n",
            "\n",
            "Downloading data for AMD...\n",
            "AMD: Got 814 prices from 2010-01-01 00:00:00-05:00 to 2025-08-01 00:00:00-04:00\n",
            "Successfully processed AMD (full history)\n",
            "\n",
            "Downloading data for AMGN...\n",
            "AMGN: Got 814 prices from 2010-01-01 00:00:00-05:00 to 2025-08-01 00:00:00-04:00\n",
            "Successfully processed AMGN (full history)\n",
            "\n",
            "Downloading data for INTU...\n",
            "INTU: Got 814 prices from 2010-01-01 00:00:00-05:00 to 2025-08-01 00:00:00-04:00\n",
            "Successfully processed INTU (full history)\n",
            "\n",
            "Downloading data for ISRG...\n",
            "ISRG: Got 814 prices from 2010-01-01 00:00:00-05:00 to 2025-08-01 00:00:00-04:00\n",
            "Successfully processed ISRG (full history)\n",
            "\n",
            "Downloading data for BKNG...\n",
            "BKNG: Got 814 prices from 2010-01-01 00:00:00-05:00 to 2025-08-01 00:00:00-04:00\n",
            "Successfully processed BKNG (full history)\n",
            "\n",
            "Downloading data for MDLZ...\n",
            "MDLZ: Got 814 prices from 2010-01-01 00:00:00-05:00 to 2025-08-01 00:00:00-04:00\n",
            "Successfully processed MDLZ (full history)\n",
            "\n",
            "Downloading data for ADI...\n",
            "ADI: Got 814 prices from 2010-01-01 00:00:00-05:00 to 2025-08-01 00:00:00-04:00\n",
            "Successfully processed ADI (full history)\n",
            "\n",
            "Downloading data for LRCX...\n",
            "LRCX: Got 814 prices from 2010-01-01 00:00:00-05:00 to 2025-08-01 00:00:00-04:00\n",
            "Successfully processed LRCX (full history)\n",
            "\n",
            "Downloading data for VRTX...\n",
            "VRTX: Got 814 prices from 2010-01-01 00:00:00-05:00 to 2025-08-01 00:00:00-04:00\n",
            "Successfully processed VRTX (full history)\n",
            "\n",
            "Downloading data for MU...\n",
            "MU: Got 814 prices from 2010-01-01 00:00:00-05:00 to 2025-08-01 00:00:00-04:00\n",
            "Successfully processed MU (full history)\n",
            "\n",
            "Downloading data for AMAT...\n",
            "AMAT: Got 814 prices from 2010-01-01 00:00:00-05:00 to 2025-08-01 00:00:00-04:00\n",
            "Successfully processed AMAT (full history)\n",
            "\n",
            "Downloading data for SBUX...\n",
            "SBUX: Got 814 prices from 2010-01-01 00:00:00-05:00 to 2025-08-01 00:00:00-04:00\n",
            "Successfully processed SBUX (full history)\n",
            "\n",
            "Downloading data for GILD...\n",
            "GILD: Got 814 prices from 2010-01-01 00:00:00-05:00 to 2025-08-01 00:00:00-04:00\n",
            "Successfully processed GILD (full history)\n",
            "\n",
            "Downloading data for MRNA...\n",
            "MRNA: Got 349 prices from 2018-12-03 00:00:00-05:00 to 2025-08-04 00:00:00-04:00\n",
            "Skipping MRNA - insufficient history (starts from 2018-12-03 00:00:00-05:00)\n",
            "\n",
            "Downloading data for ADP...\n",
            "ADP: Got 814 prices from 2010-01-01 00:00:00-05:00 to 2025-08-01 00:00:00-04:00\n",
            "Successfully processed ADP (full history)\n",
            "\n",
            "Downloading data for PANW...\n",
            "PANW: Got 682 prices from 2012-07-16 00:00:00-04:00 to 2025-08-04 00:00:00-04:00\n",
            "Successfully processed PANW (full history)\n",
            "\n",
            "Downloading data for FISV...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:yfinance:$FISV: possibly delisted; no timezone found\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No data available for FISV\n",
            "\n",
            "Downloading data for CSX...\n",
            "CSX: Got 814 prices from 2010-01-01 00:00:00-05:00 to 2025-08-01 00:00:00-04:00\n",
            "Successfully processed CSX (full history)\n",
            "\n",
            "Downloading data for REGN...\n",
            "REGN: Got 814 prices from 2010-01-01 00:00:00-05:00 to 2025-08-01 00:00:00-04:00\n",
            "Successfully processed REGN (full history)\n",
            "\n",
            "Downloading data for MNST...\n",
            "MNST: Got 814 prices from 2010-01-01 00:00:00-05:00 to 2025-08-01 00:00:00-04:00\n",
            "Successfully processed MNST (full history)\n",
            "\n",
            "Downloading data for KLAC...\n",
            "KLAC: Got 814 prices from 2010-01-01 00:00:00-05:00 to 2025-08-01 00:00:00-04:00\n",
            "Successfully processed KLAC (full history)\n",
            "\n",
            "Downloading data for MAR...\n",
            "MAR: Got 814 prices from 2010-01-01 00:00:00-05:00 to 2025-08-01 00:00:00-04:00\n",
            "Successfully processed MAR (full history)\n",
            "\n",
            "Downloading data for NXPI...\n",
            "NXPI: Got 784 prices from 2010-08-02 00:00:00-04:00 to 2025-08-04 00:00:00-04:00\n",
            "Successfully processed NXPI (full history)\n",
            "\n",
            "Downloading data for ORLY...\n",
            "ORLY: Got 814 prices from 2010-01-01 00:00:00-05:00 to 2025-08-01 00:00:00-04:00\n",
            "Successfully processed ORLY (full history)\n",
            "\n",
            "Downloading data for ADSK...\n",
            "ADSK: Got 814 prices from 2010-01-01 00:00:00-05:00 to 2025-08-01 00:00:00-04:00\n",
            "Successfully processed ADSK (full history)\n",
            "\n",
            "Downloading data for MCHP...\n",
            "MCHP: Got 814 prices from 2010-01-01 00:00:00-05:00 to 2025-08-01 00:00:00-04:00\n",
            "Successfully processed MCHP (full history)\n",
            "\n",
            "Downloading data for AEP...\n",
            "AEP: Got 814 prices from 2010-01-01 00:00:00-05:00 to 2025-08-01 00:00:00-04:00\n",
            "Successfully processed AEP (full history)\n",
            "\n",
            "Downloading data for KDP...\n",
            "KDP: Got 814 prices from 2010-01-01 00:00:00-05:00 to 2025-08-01 00:00:00-04:00\n",
            "Successfully processed KDP (full history)\n",
            "\n",
            "Downloading data for SNPS...\n",
            "SNPS: Got 814 prices from 2010-01-01 00:00:00-05:00 to 2025-08-01 00:00:00-04:00\n",
            "Successfully processed SNPS (full history)\n",
            "\n",
            "Downloading data for FTNT...\n",
            "FTNT: Got 814 prices from 2010-01-01 00:00:00-05:00 to 2025-08-01 00:00:00-04:00\n",
            "Successfully processed FTNT (full history)\n",
            "\n",
            "Downloading data for IDXX...\n",
            "IDXX: Got 814 prices from 2010-01-01 00:00:00-05:00 to 2025-08-01 00:00:00-04:00\n",
            "Successfully processed IDXX (full history)\n",
            "\n",
            "Downloading data for LULU...\n",
            "LULU: Got 814 prices from 2010-01-01 00:00:00-05:00 to 2025-08-01 00:00:00-04:00\n",
            "Successfully processed LULU (full history)\n",
            "\n",
            "Downloading data for EXC...\n",
            "EXC: Got 814 prices from 2010-01-01 00:00:00-05:00 to 2025-08-01 00:00:00-04:00\n",
            "Successfully processed EXC (full history)\n",
            "\n",
            "Downloading data for CTAS...\n",
            "CTAS: Got 814 prices from 2010-01-01 00:00:00-05:00 to 2025-08-01 00:00:00-04:00\n",
            "Successfully processed CTAS (full history)\n",
            "\n",
            "Downloading data for PAYX...\n",
            "PAYX: Got 814 prices from 2010-01-01 00:00:00-05:00 to 2025-08-01 00:00:00-04:00\n",
            "Successfully processed PAYX (full history)\n",
            "\n",
            "Downloading data for XEL...\n",
            "XEL: Got 814 prices from 2010-01-01 00:00:00-05:00 to 2025-08-01 00:00:00-04:00\n",
            "Successfully processed XEL (full history)\n",
            "\n",
            "Downloading data for PCAR...\n",
            "PCAR: Got 814 prices from 2010-01-01 00:00:00-05:00 to 2025-08-01 00:00:00-04:00\n",
            "Successfully processed PCAR (full history)\n",
            "\n",
            "Downloading data for ODFL...\n",
            "ODFL: Got 814 prices from 2010-01-01 00:00:00-05:00 to 2025-08-01 00:00:00-04:00\n",
            "Successfully processed ODFL (full history)\n",
            "\n",
            "Downloading data for VRSK...\n",
            "VRSK: Got 814 prices from 2010-01-01 00:00:00-05:00 to 2025-08-01 00:00:00-04:00\n",
            "Successfully processed VRSK (full history)\n",
            "\n",
            "Downloading data for WBA...\n",
            "WBA: Got 814 prices from 2010-01-01 00:00:00-05:00 to 2025-08-01 00:00:00-04:00\n",
            "Successfully processed WBA (full history)\n",
            "\n",
            "Downloading data for CDNS...\n",
            "CDNS: Got 814 prices from 2010-01-01 00:00:00-05:00 to 2025-08-01 00:00:00-04:00\n",
            "Successfully processed CDNS (full history)\n",
            "\n",
            "Downloading data for AZN...\n",
            "AZN: Got 814 prices from 2010-01-01 00:00:00-05:00 to 2025-08-01 00:00:00-04:00\n",
            "Successfully processed AZN (full history)\n",
            "\n",
            "Downloading data for DLTR...\n",
            "DLTR: Got 814 prices from 2010-01-01 00:00:00-05:00 to 2025-08-01 00:00:00-04:00\n",
            "Successfully processed DLTR (full history)\n",
            "\n",
            "Downloading data for EBAY...\n",
            "EBAY: Got 814 prices from 2010-01-01 00:00:00-05:00 to 2025-08-01 00:00:00-04:00\n",
            "Successfully processed EBAY (full history)\n",
            "\n",
            "Downloading data for BIIB...\n",
            "BIIB: Got 814 prices from 2010-01-01 00:00:00-05:00 to 2025-08-01 00:00:00-04:00\n",
            "Successfully processed BIIB (full history)\n",
            "\n",
            "Downloading data for ROST...\n",
            "ROST: Got 814 prices from 2010-01-01 00:00:00-05:00 to 2025-08-01 00:00:00-04:00\n",
            "Successfully processed ROST (full history)\n",
            "\n",
            "Downloading data for CRWD...\n",
            "CRWD: Got 322 prices from 2019-06-10 00:00:00-04:00 to 2025-08-04 00:00:00-04:00\n",
            "Skipping CRWD - insufficient history (starts from 2019-06-10 00:00:00-04:00)\n",
            "\n",
            "Downloading data for CHTR...\n",
            "CHTR: Got 814 prices from 2010-01-04 00:00:00-05:00 to 2025-08-04 00:00:00-04:00\n",
            "Successfully processed CHTR (full history)\n",
            "\n",
            "Downloading data for FAST...\n",
            "FAST: Got 814 prices from 2010-01-01 00:00:00-05:00 to 2025-08-01 00:00:00-04:00\n",
            "Successfully processed FAST (full history)\n",
            "\n",
            "Downloading data for PDD...\n",
            "PDD: Got 368 prices from 2018-07-23 00:00:00-04:00 to 2025-08-04 00:00:00-04:00\n",
            "Skipping PDD - insufficient history (starts from 2018-07-23 00:00:00-04:00)\n",
            "\n",
            "Downloading data for ANSS...\n",
            "ANSS: Got 811 prices from 2010-01-01 00:00:00-05:00 to 2025-07-11 00:00:00-04:00\n",
            "Successfully processed ANSS (full history)\n",
            "\n",
            "Downloading data for MRVL...\n",
            "MRVL: Got 814 prices from 2010-01-01 00:00:00-05:00 to 2025-08-01 00:00:00-04:00\n",
            "Successfully processed MRVL (full history)\n",
            "\n",
            "Downloading data for TEAM...\n",
            "TEAM: Got 505 prices from 2015-12-07 00:00:00-05:00 to 2025-08-04 00:00:00-04:00\n",
            "Skipping TEAM - insufficient history (starts from 2015-12-07 00:00:00-05:00)\n",
            "\n",
            "Downloading data for WDAY...\n",
            "WDAY: Got 670 prices from 2012-10-08 00:00:00-04:00 to 2025-08-04 00:00:00-04:00\n",
            "Successfully processed WDAY (full history)\n",
            "\n",
            "Downloading data for BKR...\n",
            "BKR: Got 814 prices from 2010-01-01 00:00:00-05:00 to 2025-08-01 00:00:00-04:00\n",
            "Successfully processed BKR (full history)\n",
            "\n",
            "Downloading data for DDOG...\n",
            "DDOG: Got 308 prices from 2019-09-16 00:00:00-04:00 to 2025-08-04 00:00:00-04:00\n",
            "Skipping DDOG - insufficient history (starts from 2019-09-16 00:00:00-04:00)\n",
            "\n",
            "Downloading data for ZS...\n",
            "ZS: Got 387 prices from 2018-03-12 00:00:00-04:00 to 2025-08-04 00:00:00-04:00\n",
            "Skipping ZS - insufficient history (starts from 2018-03-12 00:00:00-04:00)\n",
            "\n",
            "Downloading data for CEG...\n",
            "CEG: Got 186 prices from 2022-01-17 00:00:00-05:00 to 2025-08-04 00:00:00-04:00\n",
            "Skipping CEG - insufficient history (starts from 2022-01-17 00:00:00-05:00)\n",
            "\n",
            "Downloading data for KHC...\n",
            "KHC: Got 527 prices from 2015-07-06 00:00:00-04:00 to 2025-08-04 00:00:00-04:00\n",
            "Skipping KHC - insufficient history (starts from 2015-07-06 00:00:00-04:00)\n",
            "\n",
            "Downloading data for VRSN...\n",
            "VRSN: Got 814 prices from 2010-01-01 00:00:00-05:00 to 2025-08-01 00:00:00-04:00\n",
            "Successfully processed VRSN (full history)\n",
            "\n",
            "Downloading data for CTSH...\n",
            "CTSH: Got 814 prices from 2010-01-01 00:00:00-05:00 to 2025-08-01 00:00:00-04:00\n",
            "Successfully processed CTSH (full history)\n",
            "\n",
            "Downloading data for SWKS...\n",
            "SWKS: Got 814 prices from 2010-01-01 00:00:00-05:00 to 2025-08-01 00:00:00-04:00\n",
            "Successfully processed SWKS (full history)\n",
            "\n",
            "Downloading data for OKTA...\n",
            "OKTA: Got 436 prices from 2017-04-03 00:00:00-04:00 to 2025-08-04 00:00:00-04:00\n",
            "Skipping OKTA - insufficient history (starts from 2017-04-03 00:00:00-04:00)\n",
            "\n",
            "Downloading data for EA...\n",
            "EA: Got 814 prices from 2010-01-01 00:00:00-05:00 to 2025-08-01 00:00:00-04:00\n",
            "Successfully processed EA (full history)\n",
            "\n",
            "Downloading data for LCID...\n",
            "LCID: Got 256 prices from 2020-09-14 00:00:00-04:00 to 2025-08-04 00:00:00-04:00\n",
            "Skipping LCID - insufficient history (starts from 2020-09-14 00:00:00-04:00)\n",
            "\n",
            "Downloading data for BIDU...\n",
            "BIDU: Got 814 prices from 2010-01-01 00:00:00-05:00 to 2025-08-01 00:00:00-04:00\n",
            "Successfully processed BIDU (full history)\n",
            "\n",
            "Downloading data for ALGN...\n",
            "ALGN: Got 814 prices from 2010-01-01 00:00:00-05:00 to 2025-08-01 00:00:00-04:00\n",
            "Successfully processed ALGN (full history)\n",
            "\n",
            "Downloading data for MELI...\n",
            "MELI: Got 814 prices from 2010-01-01 00:00:00-05:00 to 2025-08-01 00:00:00-04:00\n",
            "Successfully processed MELI (full history)\n",
            "\n",
            "Downloading data for JD...\n",
            "JD: Got 586 prices from 2014-05-19 00:00:00-04:00 to 2025-08-04 00:00:00-04:00\n",
            "Successfully processed JD (full history)\n",
            "\n",
            "Downloading data for LI...\n",
            "LI: Got 263 prices from 2020-07-27 00:00:00-04:00 to 2025-08-04 00:00:00-04:00\n",
            "Skipping LI - insufficient history (starts from 2020-07-27 00:00:00-04:00)\n",
            "\n",
            "Downloading data for NTES...\n",
            "NTES: Got 814 prices from 2010-01-01 00:00:00-05:00 to 2025-08-01 00:00:00-04:00\n",
            "Successfully processed NTES (full history)\n",
            "\n",
            "Downloading data for ASML...\n",
            "ASML: Got 814 prices from 2010-01-01 00:00:00-05:00 to 2025-08-01 00:00:00-04:00\n",
            "Successfully processed ASML (full history)\n",
            "\n",
            "Downloading data for DXCM...\n",
            "DXCM: Got 814 prices from 2010-01-01 00:00:00-05:00 to 2025-08-01 00:00:00-04:00\n",
            "Successfully processed DXCM (full history)\n",
            "\n",
            "Downloading data for CPRT...\n",
            "CPRT: Got 814 prices from 2010-01-01 00:00:00-05:00 to 2025-08-01 00:00:00-04:00\n",
            "Successfully processed CPRT (full history)\n",
            "\n",
            "Download Summary:\n",
            "Successfully downloaded: 81 stocks\n",
            "Failed downloads: 12 stocks\n",
            "Stocks with complete history from 2014: 81\n",
            "\n",
            "Shape of combined data: (1628, 81)\n",
            "\n",
            "Date range in data:\n",
            "Start: 2010-01-01 00:00:00-05:00\n",
            "End: 2025-08-04 00:00:00-04:00\n",
            "\n",
            "Stocks in dataset: 81\n",
            "\n",
            "First few rows of the data:\n",
            "                               AAPL       MSFT       GOOG    AMZN      NVDA  \\\n",
            "Date                                                                          \n",
            "2010-01-01 00:00:00-05:00  6.328810  22.836456  14.709600  6.5000  0.424313   \n",
            "2010-01-04 00:00:00-05:00       NaN        NaN        NaN     NaN       NaN   \n",
            "2010-01-08 00:00:00-05:00  6.294250  23.218939  14.604374  6.3675  0.404140   \n",
            "2010-01-11 00:00:00-05:00       NaN        NaN        NaN     NaN       NaN   \n",
            "2010-01-15 00:00:00-05:00  6.253374  22.506472  14.434276  6.3310  0.390844   \n",
            "\n",
            "                           META  TSLA        PEP      AVGO       COST  ...  \\\n",
            "Date                                                                   ...   \n",
            "2010-01-01 00:00:00-05:00   NaN   NaN  38.538269  1.345404  42.434757  ...   \n",
            "2010-01-04 00:00:00-05:00   NaN   NaN        NaN       NaN        NaN  ...   \n",
            "2010-01-08 00:00:00-05:00   NaN   NaN  39.694984  1.302985  41.731174  ...   \n",
            "2010-01-11 00:00:00-05:00   NaN   NaN        NaN       NaN        NaN  ...   \n",
            "2010-01-15 00:00:00-05:00   NaN   NaN  38.519310  1.271877  40.878365  ...   \n",
            "\n",
            "                                SWKS         EA       BIDU       ALGN  \\\n",
            "Date                                                                    \n",
            "2010-01-01 00:00:00-05:00  12.020520  17.575985  40.463001  17.430000   \n",
            "2010-01-04 00:00:00-05:00        NaN        NaN        NaN        NaN   \n",
            "2010-01-08 00:00:00-05:00  12.501670  16.738104  46.423000  17.129999   \n",
            "2010-01-11 00:00:00-05:00        NaN        NaN        NaN        NaN   \n",
            "2010-01-15 00:00:00-05:00  11.824801  16.932961  43.997002  16.850000   \n",
            "\n",
            "                                MELI  JD      NTES       ASML    DXCM  \\\n",
            "Date                                                                    \n",
            "2010-01-01 00:00:00-05:00  48.701820 NaN  6.412515  32.599827  2.3025   \n",
            "2010-01-04 00:00:00-05:00        NaN NaN       NaN        NaN     NaN   \n",
            "2010-01-08 00:00:00-05:00  41.880093 NaN  6.188014  31.838806  2.3050   \n",
            "2010-01-11 00:00:00-05:00        NaN NaN       NaN        NaN     NaN   \n",
            "2010-01-15 00:00:00-05:00  40.087437 NaN  5.652057  31.553417  2.4375   \n",
            "\n",
            "                               CPRT  \n",
            "Date                                 \n",
            "2010-01-01 00:00:00-05:00  2.252500  \n",
            "2010-01-04 00:00:00-05:00       NaN  \n",
            "2010-01-08 00:00:00-05:00  2.233750  \n",
            "2010-01-11 00:00:00-05:00       NaN  \n",
            "2010-01-15 00:00:00-05:00  2.175625  \n",
            "\n",
            "[5 rows x 81 columns]\n",
            "\n",
            "Included stocks with complete history:\n",
            "AAPL, ADBE, ADI, ADP, ADSK, AEP, ALGN, AMAT, AMD, AMGN, AMZN, ANSS, ASML, AVGO, AZN, BIDU, BIIB, BKNG, BKR, CDNS, CHTR, CMCSA, COST, CPRT, CSCO, CSX, CTAS, CTSH, DLTR, DXCM, EA, EBAY, EXC, FAST, FTNT, GILD, GOOG, HON, IDXX, INTC, INTU, ISRG, JD, KDP, KLAC, LRCX, LULU, MAR, MCHP, MDLZ, MELI, META, MNST, MRVL, MSFT, MU, NFLX, NTES, NVDA, NXPI, ODFL, ORLY, PANW, PAYX, PCAR, PEP, QCOM, REGN, ROST, SBUX, SNPS, SWKS, TMUS, TSLA, TXN, VRSK, VRSN, VRTX, WBA, WDAY, XEL\n"
          ]
        }
      ],
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import time\n",
        "\n",
        "# Define the ticker symbols for the stocks\n",
        "ticker_symbols = [\n",
        "    \"AAPL\", \"MSFT\", \"GOOG\", \"AMZN\", \"NVDA\", \"META\", \"TSLA\", \"PEP\", \"AVGO\",\n",
        "    \"COST\", \"CSCO\", \"ADBE\", \"NFLX\", \"TMUS\", \"TXN\", \"CMCSA\", \"QCOM\", \"INTC\", \"HON\",\n",
        "    \"AMD\", \"AMGN\", \"INTU\", \"ISRG\", \"BKNG\", \"MDLZ\", \"ADI\", \"LRCX\", \"VRTX\", \"MU\",\n",
        "    \"AMAT\", \"SBUX\", \"GILD\", \"MRNA\", \"ADP\", \"PANW\", \"FISV\", \"CSX\", \"REGN\", \"MNST\",\n",
        "    \"KLAC\", \"MAR\", \"NXPI\", \"ORLY\", \"ADSK\", \"MCHP\", \"AEP\", \"KDP\", \"SNPS\",\n",
        "    \"FTNT\", \"IDXX\", \"LULU\", \"EXC\", \"CTAS\", \"PAYX\", \"XEL\", \"PCAR\", \"ODFL\", \"VRSK\",\n",
        "    \"WBA\", \"CDNS\", \"AZN\", \"DLTR\", \"EBAY\", \"BIIB\", \"ROST\", \"CRWD\", \"CHTR\",\n",
        "    \"FAST\", \"PDD\", \"ANSS\", \"MRVL\", \"TEAM\", \"WDAY\", \"BKR\", \"DDOG\", \"ZS\", \"CEG\",\n",
        "    \"KHC\", \"VRSN\", \"CTSH\", \"SWKS\", \"OKTA\", \"EA\", \"LCID\", \"BIDU\", \"ALGN\",\n",
        "    \"MELI\", \"JD\", \"LI\", \"NTES\", \"ASML\", \"DXCM\", \"CPRT\"\n",
        "]\n",
        "\n",
        "# Parameters - all UTC timestamps\n",
        "startdate = '2010-01-01'\n",
        "enddate = '2025-12-31'\n",
        "cutoff_date = '2014-07-01'\n",
        "\n",
        "mom_p = 20 #26\n",
        "vol_p = 35\n",
        "RSI_p = 40\n",
        "ass_amount = 6\n",
        "MA_p = 40\n",
        "cor_p = 40 # monthly\n",
        "\n",
        "# Create reference timestamps with timezone\n",
        "START_TS = pd.Timestamp(startdate).tz_localize('UTC')\n",
        "END_TS = pd.Timestamp(enddate).tz_localize('UTC')\n",
        "CUTOFF_TS = pd.Timestamp(cutoff_date).tz_localize('UTC')\n",
        "\n",
        "def download_stock_data(ticker):\n",
        "    \"\"\"\n",
        "    Download stock data for a single ticker with improved error handling.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        print(f\"\\nDownloading data for {ticker}...\")\n",
        "\n",
        "        # Create a Ticker object\n",
        "        stock = yf.Ticker(ticker)\n",
        "\n",
        "        # Download the historical data\n",
        "        data = stock.history(\n",
        "            start=startdate,\n",
        "            end=enddate,\n",
        "            interval='1wk',\n",
        "            auto_adjust=True  # This ensures we get adjusted prices\n",
        "        )\n",
        "\n",
        "        if data.empty:\n",
        "            print(f\"No data available for {ticker}\")\n",
        "            return None\n",
        "\n",
        "        # Extract the closing prices\n",
        "        prices = data['Close']  # Use 'Close' instead of 'Adj Close' since auto_adjust=True\n",
        "\n",
        "        # Verify we have actual price data\n",
        "        if len(prices) == 0:\n",
        "            print(f\"No price data for {ticker}\")\n",
        "            return None\n",
        "\n",
        "        print(f\"{ticker}: Got {len(prices)} prices from {prices.index[0]} to {prices.index[-1]}\")\n",
        "\n",
        "        # Add a small delay to avoid rate limiting\n",
        "        time.sleep(1)  # Increased delay to be more conservative\n",
        "\n",
        "        return prices\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error downloading {ticker}: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "def main():\n",
        "    print(\"Starting download of stock data...\")\n",
        "\n",
        "    # Download and store the data\n",
        "    all_data = {}\n",
        "    successful_downloads = 0\n",
        "    failed_downloads = 0\n",
        "    long_history_tickers = []\n",
        "\n",
        "    # Convert cutoff date to timezone-aware pandas timestamp\n",
        "    cutoff = pd.Timestamp(cutoff_date, tz='UTC')\n",
        "\n",
        "    # First pass: Download all data and identify stocks with sufficient history\n",
        "    for ticker in ticker_symbols:\n",
        "        series = download_stock_data(ticker)\n",
        "        if series is not None and not series.empty:\n",
        "            # Ensure index is timezone aware\n",
        "            if series.index.tz is None:\n",
        "                series.index = series.index.tz_localize('UTC')\n",
        "            # Check if the stock has data from before our cutoff date\n",
        "            if series.index[0] <= CUTOFF_TS:\n",
        "                long_history_tickers.append(ticker)\n",
        "                all_data[ticker] = series\n",
        "                successful_downloads += 1\n",
        "                print(f\"Successfully processed {ticker} (full history)\")\n",
        "            else:\n",
        "                print(f\"Skipping {ticker} - insufficient history (starts from {series.index[0]})\")\n",
        "                failed_downloads += 1\n",
        "        else:\n",
        "            failed_downloads += 1\n",
        "\n",
        "    # Create DataFrame and save results\n",
        "    if all_data:\n",
        "        # Convert to DataFrame\n",
        "        combined_data = pd.DataFrame(all_data)\n",
        "\n",
        "        # Save to CSV\n",
        "        combined_data.to_csv('combined_stock_data.csv')\n",
        "\n",
        "        print(\"\\nDownload Summary:\")\n",
        "        print(f\"Successfully downloaded: {successful_downloads} stocks\")\n",
        "        print(f\"Failed downloads: {failed_downloads} stocks\")\n",
        "        print(f\"Stocks with complete history from 2014: {len(long_history_tickers)}\")\n",
        "        print(f\"\\nShape of combined data: {combined_data.shape}\")\n",
        "        print(\"\\nDate range in data:\")\n",
        "        print(f\"Start: {combined_data.index[0]}\")\n",
        "        print(f\"End: {combined_data.index[-1]}\")\n",
        "        print(f\"\\nStocks in dataset: {len(combined_data.columns)}\")\n",
        "        print(\"\\nFirst few rows of the data:\")\n",
        "        print(combined_data.head())\n",
        "\n",
        "        # Print list of included stocks\n",
        "        print(\"\\nIncluded stocks with complete history:\")\n",
        "        print(', '.join(sorted(long_history_tickers)))\n",
        "\n",
        "    else:\n",
        "        print(\"\\nNo data was successfully downloaded!\")\n",
        "        print(f\"Attempted downloads: {len(ticker_symbols)}\")\n",
        "        print(f\"Failed downloads: {failed_downloads}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wCe5j8lLFQAd"
      },
      "outputs": [],
      "source": [
        "def load_stock_data(filepath='combined_stock_data.csv'):\n",
        "    combined_data = pd.read_csv(filepath, index_col=0, parse_dates=True)\n",
        "    combined_data.index = pd.to_datetime(combined_data.index, utc=True)\n",
        "    return combined_data\n",
        "\n",
        "combined_data = load_stock_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 618
        },
        "id": "R7BLBRBkJMOA",
        "outputId": "e4bff454-5728-4b2a-eafd-a3d614ca8faf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-302948307.py:1: FutureWarning:\n",
            "\n",
            "The default fill_method='pad' in DataFrame.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
            "\n",
            "/tmp/ipython-input-302948307.py:3: FutureWarning:\n",
            "\n",
            "'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                           AAPL  MSFT  GOOG  AMZN  NVDA  META  TSLA   PEP  \\\n",
              "Date                                                                        \n",
              "2010-01-31 00:00:00+00:00   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
              "2010-02-28 00:00:00+00:00   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
              "2010-03-31 00:00:00+00:00   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
              "2010-04-30 00:00:00+00:00   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
              "2010-05-31 00:00:00+00:00  49.0  16.0  36.0  57.0  69.0   NaN   NaN   2.0   \n",
              "...                         ...   ...   ...   ...   ...   ...   ...   ...   \n",
              "2025-04-30 00:00:00+00:00  48.0  33.0  27.0  43.0  72.0  65.0  74.0  11.0   \n",
              "2025-05-31 00:00:00+00:00  53.0  23.0  30.0  41.0  69.0  64.0  77.0   6.0   \n",
              "2025-06-30 00:00:00+00:00  58.0  24.0  26.0  37.0  64.0  69.0  79.0   8.0   \n",
              "2025-07-31 00:00:00+00:00  39.0  23.0  20.0  19.0  54.0  70.0  79.0  21.0   \n",
              "2025-08-31 00:00:00+00:00  41.0  26.0  20.0  42.0  54.0  64.0  78.0  19.0   \n",
              "\n",
              "                           AVGO  COST  ...  SWKS    EA  BIDU  ALGN  MELI  \\\n",
              "Date                                   ...                                 \n",
              "2010-01-31 00:00:00+00:00   NaN   NaN  ...   NaN   NaN   NaN   NaN   NaN   \n",
              "2010-02-28 00:00:00+00:00   NaN   NaN  ...   NaN   NaN   NaN   NaN   NaN   \n",
              "2010-03-31 00:00:00+00:00   NaN   NaN  ...   NaN   NaN   NaN   NaN   NaN   \n",
              "2010-04-30 00:00:00+00:00   NaN   NaN  ...   NaN   NaN   NaN   NaN   NaN   \n",
              "2010-05-31 00:00:00+00:00  50.0   3.0  ...  59.0  34.0  68.0  47.0  75.0   \n",
              "...                         ...   ...  ...   ...   ...   ...   ...   ...   \n",
              "2025-04-30 00:00:00+00:00  73.0  35.0  ...  76.0  56.0  69.0  57.0  30.0   \n",
              "2025-05-31 00:00:00+00:00  73.0  33.0  ...  76.0  28.0  62.0  57.0  29.0   \n",
              "2025-06-30 00:00:00+00:00  73.0  30.0  ...  63.0  15.0  55.0  53.0  49.0   \n",
              "2025-07-31 00:00:00+00:00  62.0   3.0  ...  53.0  22.0  51.0  81.0  47.0   \n",
              "2025-08-31 00:00:00+00:00  53.0   3.0  ...  50.0  24.0  32.0  81.0  48.0   \n",
              "\n",
              "                             JD  NTES  ASML  DXCM  CPRT  \n",
              "Date                                                     \n",
              "2010-01-31 00:00:00+00:00   NaN   NaN   NaN   NaN   NaN  \n",
              "2010-02-28 00:00:00+00:00   NaN   NaN   NaN   NaN   NaN  \n",
              "2010-03-31 00:00:00+00:00   NaN   NaN   NaN   NaN   NaN  \n",
              "2010-04-30 00:00:00+00:00   NaN   NaN   NaN   NaN   NaN  \n",
              "2010-05-31 00:00:00+00:00   NaN  65.0  45.0  70.0  17.0  \n",
              "...                         ...   ...   ...   ...   ...  \n",
              "2025-04-30 00:00:00+00:00  62.0  37.0  40.0  68.0   6.0  \n",
              "2025-05-31 00:00:00+00:00  25.0  55.0  47.0  75.0  38.0  \n",
              "2025-06-30 00:00:00+00:00  31.0  60.0  45.0  77.0  40.0  \n",
              "2025-07-31 00:00:00+00:00  55.0  64.0  40.0  68.0  48.0  \n",
              "2025-08-31 00:00:00+00:00  47.0  56.0  43.0  72.0  49.0  \n",
              "\n",
              "[188 rows x 81 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-66c81340-9de5-49d2-be65-9729b5626f99\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AAPL</th>\n",
              "      <th>MSFT</th>\n",
              "      <th>GOOG</th>\n",
              "      <th>AMZN</th>\n",
              "      <th>NVDA</th>\n",
              "      <th>META</th>\n",
              "      <th>TSLA</th>\n",
              "      <th>PEP</th>\n",
              "      <th>AVGO</th>\n",
              "      <th>COST</th>\n",
              "      <th>...</th>\n",
              "      <th>SWKS</th>\n",
              "      <th>EA</th>\n",
              "      <th>BIDU</th>\n",
              "      <th>ALGN</th>\n",
              "      <th>MELI</th>\n",
              "      <th>JD</th>\n",
              "      <th>NTES</th>\n",
              "      <th>ASML</th>\n",
              "      <th>DXCM</th>\n",
              "      <th>CPRT</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2010-01-31 00:00:00+00:00</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-02-28 00:00:00+00:00</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-03-31 00:00:00+00:00</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-04-30 00:00:00+00:00</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-05-31 00:00:00+00:00</th>\n",
              "      <td>49.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>57.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>...</td>\n",
              "      <td>59.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>65.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>17.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-04-30 00:00:00+00:00</th>\n",
              "      <td>48.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>73.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>...</td>\n",
              "      <td>76.0</td>\n",
              "      <td>56.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>57.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-05-31 00:00:00+00:00</th>\n",
              "      <td>53.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>77.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>73.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>...</td>\n",
              "      <td>76.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>57.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>38.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-06-30 00:00:00+00:00</th>\n",
              "      <td>58.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>73.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>...</td>\n",
              "      <td>63.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>53.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>77.0</td>\n",
              "      <td>40.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-07-31 00:00:00+00:00</th>\n",
              "      <td>39.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>...</td>\n",
              "      <td>53.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>81.0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>48.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-08-31 00:00:00+00:00</th>\n",
              "      <td>41.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>78.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>53.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>...</td>\n",
              "      <td>50.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>81.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>56.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>49.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>188 rows  81 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-66c81340-9de5-49d2-be65-9729b5626f99')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-66c81340-9de5-49d2-be65-9729b5626f99 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-66c81340-9de5-49d2-be65-9729b5626f99');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-3865cd37-6c6f-49f7-a289-612c80086bc8\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3865cd37-6c6f-49f7-a289-612c80086bc8')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-3865cd37-6c6f-49f7-a289-612c80086bc8 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_3e62a4f5-95ea-4f47-b0df-f6a5f992f431\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('ranked_volatility')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_3e62a4f5-95ea-4f47-b0df-f6a5f992f431 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('ranked_volatility');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "ranked_volatility"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "price_changes = combined_data.pct_change()\n",
        "volatility = price_changes.rolling(window= vol_p ).std()\n",
        "volatility_monthly = volatility.resample('M').last()\n",
        "ranked_volatility = volatility_monthly.rank(axis=1, method='first')\n",
        "\n",
        "ranked_volatility"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQqOqHSr-k3w",
        "outputId": "78a9617a-72b1-4379-9798-1538830b7e06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3057405011.py:1: FutureWarning:\n",
            "\n",
            "The default fill_method='pad' in DataFrame.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "price_changes = combined_data.pct_change()\n",
        "\n",
        "mask1 = combined_data < combined_data.shift(mom_p)\n",
        "\n",
        "moving_average = combined_data.rolling(window=MA_p).mean()\n",
        "mask2 = combined_data < moving_average\n",
        "\n",
        "price_changes = price_changes.where(~(mask1 | mask2))\n",
        "\n",
        "momentum = price_changes.rolling(window=mom_p).apply(lambda x: (x + 1).prod() - 1)\n",
        "\n",
        "momentum_monthly = momentum.resample('M').last()\n",
        "\n",
        "ranked_momentum = momentum_monthly.rank(axis=1, method='first', ascending=False)\n",
        "\n",
        "ranked_momentum.to_csv('ranked_momentum.csv')\n",
        "\n",
        "ranked_momentum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cQTN7Na-KFcW"
      },
      "outputs": [],
      "source": [
        "pct_change_df = combined_data.pct_change()\n",
        "\n",
        "correlation_means = []\n",
        "\n",
        "for index, row in pct_change_df.iterrows():\n",
        "    other_tickers = [ticker for ticker in pct_change_df.columns if ticker != index]\n",
        "    correlation_mean = row.corr(pct_change_df[other_tickers].mean(axis=1))\n",
        "    correlation_means.append(correlation_mean)\n",
        "\n",
        "pct_change_df['Correlation_Mean'] = correlation_means\n",
        "pct_change_df = pct_change_df.drop('Correlation_Mean', axis=1)\n",
        "\n",
        "resampled_df = pct_change_df.resample('M').mean()\n",
        "rolling_mean_df = resampled_df.rolling(window=cor_p).mean()\n",
        "rolling_mean_df = rolling_mean_df.shift(-1)\n",
        "rolling_mean_df = rolling_mean_df.iloc[:-1]\n",
        "\n",
        "rankings_df = rolling_mean_df\n",
        "\n",
        "ranked_correlation = rolling_mean_df.rank(axis=1, method='first')\n",
        "\n",
        "ranked_correlation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DgFj2IluZXXg"
      },
      "outputs": [],
      "source": [
        "combined_data.index = pd.to_datetime(combined_data.index)\n",
        "\n",
        "rsi_values = pd.DataFrame(index=combined_data.index)\n",
        "\n",
        "for stock in combined_data.columns:\n",
        "    stock_changes = combined_data[stock].pct_change()\n",
        "\n",
        "    gain = stock_changes.clip(lower=0)\n",
        "    loss = -stock_changes.clip(upper=0)\n",
        "\n",
        "    avg_gain = gain.ewm(com=RSI_p, adjust=False).mean()\n",
        "    avg_loss = loss.ewm(com=RSI_p, adjust=False).mean()\n",
        "\n",
        "    rs = avg_gain / avg_loss\n",
        "    rsi = 100 - (100 / (1 + rs))\n",
        "\n",
        "    rsi_values[stock] = rsi\n",
        "\n",
        "rsi_monthly = rsi_values.resample('M').last()\n",
        "\n",
        "ranked_rsi = rsi_monthly.rank(axis=1, method='first', ascending=False)\n",
        "\n",
        "# Print the ranked RSI\n",
        "ranked_rsi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HL7x1NSVditR"
      },
      "outputs": [],
      "source": [
        "ranking_weights = pd.Series({\n",
        "    'Momentum Score': 1,\n",
        "    'RSI Score': 0,\n",
        "    'Volatility Score': 0,\n",
        "    'Correlation Score': 0\n",
        "})\n",
        "\n",
        "weighted_momentum = ranked_momentum * ranking_weights['Momentum Score']\n",
        "weighted_rsi = ranked_rsi * ranking_weights['RSI Score']\n",
        "weighted_volatility = ranked_volatility * ranking_weights['Volatility Score']\n",
        "weighted_correlation = ranked_correlation * ranking_weights['Correlation Score']\n",
        "\n",
        "cumulative_score = weighted_momentum + weighted_rsi + weighted_volatility + weighted_correlation\n",
        "\n",
        "cumulative_score.to_csv('cumscore.csv', index=True)\n",
        "\n",
        "cumulative_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R8YPLIdmZc1G"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def process_portfolio_selections(cumulative_score, ass_amount):\n",
        "    ranked_df = cumulative_score.apply(lambda x: x.nsmallest(ass_amount), axis=1)\n",
        "\n",
        "    ranked_mask = ranked_df.notna()\n",
        "\n",
        "    result_df = pd.DataFrame(index=ranked_df.index, columns=ranked_df.columns)\n",
        "    for column in ranked_df.columns:\n",
        "        result_df[column] = ranked_mask[column].map({True: column, False: 0})\n",
        "    result_df.index = pd.to_datetime(result_df.index)\n",
        "    result_df.index = result_df.index + pd.DateOffset(months=1)\n",
        "\n",
        "    dates = []\n",
        "    tickers = []\n",
        "\n",
        "    for date, row in result_df.iterrows():\n",
        "        valid_tickers = row[row != 0]\n",
        "        if not valid_tickers.empty:\n",
        "            dates.extend([date] * len(valid_tickers))\n",
        "            tickers.extend(valid_tickers.index)\n",
        "\n",
        "    non_zero_df = pd.DataFrame({\n",
        "        'Date': dates,\n",
        "        'Ticker': tickers\n",
        "    })\n",
        "\n",
        "    non_zero_df['Date'] = pd.to_datetime(non_zero_df['Date'])\n",
        "\n",
        "    return non_zero_df\n",
        "\n",
        "portfolio_selections = process_portfolio_selections(cumulative_score, ass_amount)\n",
        "\n",
        "portfolio_selections.to_csv('portfolio_selections.csv', index=False)\n",
        "\n",
        "print(\"\\nPortfolio Selections Summary:\")\n",
        "print(f\"Total number of selections: {len(portfolio_selections)}\")\n",
        "print(f\"Date range: {portfolio_selections['Date'].min()} to {portfolio_selections['Date'].max()}\")\n",
        "print(f\"Number of unique tickers: {portfolio_selections['Ticker'].nunique()}\")\n",
        "print(\"\\nFirst few selections:\")\n",
        "print(portfolio_selections.head(50))\n",
        "print(portfolio_selections.tail(6))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jmjtlUDECiUF"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "from datetime import datetime, timedelta\n",
        "import numpy as np\n",
        "from typing import Dict, List, Any\n",
        "\n",
        "def calculate_stock_return(ticker: str, start_date: pd.Timestamp, end_date: pd.Timestamp) -> Dict[str, Any]:\n",
        "    \"\"\"Calculate return for a single stock with error handling\"\"\"\n",
        "    try:\n",
        "        stock = yf.download(\n",
        "            ticker,\n",
        "            start=start_date,\n",
        "            end=end_date + timedelta(days=1),\n",
        "            progress=False,\n",
        "            ignore_tz=True,\n",
        "            auto_adjust=False # Explicitly set auto_adjust to False\n",
        "        )\n",
        "\n",
        "        if stock.empty or len(stock) < 2:\n",
        "            print(f\"Warning: Insufficient data for {ticker} between {start_date} and {end_date}\")\n",
        "            return None\n",
        "\n",
        "        # Use 'Adj Close' when auto_adjust is False\n",
        "        first_price = float(stock['Adj Close'].iloc[0].item())\n",
        "        last_price = float(stock['Adj Close'].iloc[-1].item())\n",
        "        pct_change = ((last_price - first_price) / first_price) * 100\n",
        "\n",
        "        return {\n",
        "            'Start_Price': first_price,\n",
        "            'End_Price': last_price,\n",
        "            'Return_Pct': pct_change\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {ticker} for period {start_date} to {end_date}: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "def analyze_portfolio(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Analyze portfolio returns\"\"\"\n",
        "    results = []\n",
        "\n",
        "    # Group by date to get monthly portfolios\n",
        "    monthly_portfolios = df.groupby('Date')['Ticker'].apply(list).reset_index()\n",
        "\n",
        "    total_tickers = sum(len(tickers) for tickers in monthly_portfolios['Ticker'])\n",
        "    processed = 0\n",
        "\n",
        "    for _, row in monthly_portfolios.iterrows():\n",
        "        date = pd.to_datetime(row['Date'])\n",
        "        tickers = row['Ticker']\n",
        "\n",
        "        # Calculate start and end of month\n",
        "        start_date = date.replace(day=1)\n",
        "        end_date = (start_date + pd.offsets.MonthEnd(0))\n",
        "\n",
        "        for ticker in tickers:\n",
        "            return_data = calculate_stock_return(ticker, start_date, end_date)\n",
        "            processed += 1\n",
        "\n",
        "            if return_data is not None:\n",
        "                results.append({\n",
        "                    'Date': date,\n",
        "                    'Ticker': ticker,\n",
        "                    **return_data\n",
        "                })\n",
        "\n",
        "            # Print progress\n",
        "            if processed % 100 == 0:\n",
        "                print(f\"Processed {processed}/{total_tickers} stocks\")\n",
        "\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "def format_summary(summary_df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Format the summary dataframe for better display\"\"\"\n",
        "    summary_df.index = summary_df.index.strftime('%Y-%m-%d')\n",
        "    return summary_df\n",
        "\n",
        "def print_analysis(returns_df: pd.DataFrame, summary_df: pd.DataFrame):\n",
        "    \"\"\"Print formatted analysis results\"\"\"\n",
        "    print(\"\\nPortfolio Analysis Summary:\")\n",
        "    print(f\"Total periods analyzed: {len(summary_df)}\")\n",
        "    print(f\"Total stocks analyzed: {len(returns_df)}\")\n",
        "\n",
        "    print(\"\\nFirst few rows of monthly summary:\")\n",
        "    print(format_summary(summary_df.head()))\n",
        "\n",
        "    print(\"\\nOverall Statistics:\")\n",
        "    print(f\"Average monthly return: {returns_df['Return_Pct'].mean():.2f}%\")\n",
        "    print(f\"Best monthly return: {returns_df['Return_Pct'].max():.2f}%\")\n",
        "    print(f\"Worst monthly return: {returns_df['Return_Pct'].min():.2f}%\")\n",
        "    print(f\"Return standard deviation: {returns_df['Return_Pct'].std():.2f}%\")\n",
        "\n",
        "    # Calculate annualized statistics\n",
        "    monthly_returns = returns_df.groupby('Date')['Return_Pct'].mean()\n",
        "    annualized_return = ((1 + monthly_returns/100).prod() ** (12/len(monthly_returns)) - 1) * 100\n",
        "    annualized_vol = monthly_returns.std() * np.sqrt(12)\n",
        "\n",
        "    print(f\"\\nAnnualized Statistics:\")\n",
        "    print(f\"Annualized Return: {annualized_return:.2f}%\")\n",
        "    print(f\"Annualized Volatility: {annualized_vol:.2f}%\")\n",
        "    print(f\"Sharpe Ratio (Rf=0): {(annualized_return/annualized_vol):.2f}\")\n",
        "\n",
        "# Example usage:\n",
        "if __name__ == \"__main__\":\n",
        "    # Read your CSV data\n",
        "    portfolio_df = pd.read_csv(\"portfolio_selections.csv\")\n",
        "\n",
        "    # Process returns\n",
        "    print(\"Starting portfolio analysis...\")\n",
        "    returns_df = analyze_portfolio(portfolio_df)\n",
        "\n",
        "    # Generate summary\n",
        "    summary_df = returns_df.groupby('Date').agg({\n",
        "        'Return_Pct': [\n",
        "            ('Mean Return %', 'mean'),\n",
        "            ('Std Dev %', 'std'),\n",
        "            ('Min Return %', 'min'),\n",
        "            ('Max Return %', 'max'),\n",
        "            ('Count', 'count')\n",
        "        ]\n",
        "    }).round(2)\n",
        "\n",
        "    # Flatten column names\n",
        "    summary_df.columns = summary_df.columns.get_level_values(1)\n",
        "\n",
        "    # Save results\n",
        "    returns_df.to_csv('stock_returns_detailed.csv', index=False)\n",
        "    summary_df.to_csv('monthly_summary.csv')\n",
        "\n",
        "    # Print analysis\n",
        "    print_analysis(returns_df, summary_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "DN5D6jhMOFDZ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "\n",
        "def calculate_monthly_matrix(returns_series):\n",
        "    \"\"\"Convert monthly returns to a year x month matrix\"\"\"\n",
        "    df = pd.DataFrame({'returns': returns_series})\n",
        "    df['year'] = df.index.year\n",
        "    df['month'] = df.index.month\n",
        "    return df.pivot_table(index='year', columns='month', values='returns')\n",
        "\n",
        "def create_performance_charts(returns_df, benchmark_tickers=['SPY', 'QQQ']):\n",
        "    \"\"\"Create performance visualization suite\"\"\"\n",
        "    # Convert returns to decimal\n",
        "    returns_df['Return_Pct'] = returns_df['Return_Pct'] / 100\n",
        "\n",
        "    # Calculate portfolio performance\n",
        "    monthly_returns = returns_df.groupby('Date')['Return_Pct'].mean()\n",
        "    portfolio_cum_returns = (1 + monthly_returns).cumprod()\n",
        "\n",
        "    # Download benchmark data\n",
        "    benchmark_returns = {}\n",
        "    for ticker in benchmark_tickers:\n",
        "        print(f\"\\nDownloading {ticker} data...\")\n",
        "        benchmark_data = yf.download(ticker,\n",
        "                                   start=returns_df['Date'].min(),\n",
        "                                   end=returns_df['Date'].max(),\n",
        "                                   interval='1mo',\n",
        "                                   auto_adjust=True # Use auto_adjust=True for adjusted prices\n",
        "                                   )\n",
        "        # Use 'Close' when auto_adjust=True\n",
        "        benchmark_returns[ticker] = benchmark_data['Close'].pct_change()\n",
        "\n",
        "\n",
        "    # Create figures\n",
        "    fig1 = make_subplots(rows=2, cols=1, shared_xaxes=True,\n",
        "                        subplot_titles=('Cumulative Returns (Log Scale)', 'Drawdowns'))\n",
        "\n",
        "    # Cumulative Returns Plot\n",
        "    fig1.add_trace(\n",
        "        go.Scatter(x=portfolio_cum_returns.index, y=portfolio_cum_returns,\n",
        "                  name='Portfolio', line=dict(color='blue')),\n",
        "        row=1, col=1\n",
        "    )\n",
        "\n",
        "    for ticker, returns in benchmark_returns.items():\n",
        "        # Ensure benchmark returns are aligned and cumulative\n",
        "        aligned_returns = returns.reindex(monthly_returns.index).fillna(0)\n",
        "        cum_returns = (1 + aligned_returns).cumprod()\n",
        "        fig1.add_trace(\n",
        "            go.Scatter(x=cum_returns.index, y=cum_returns,\n",
        "                      name=ticker, line=dict(dash='dash')),\n",
        "            row=1, col=1\n",
        "        )\n",
        "\n",
        "    # Drawdowns Plot\n",
        "    drawdowns = (portfolio_cum_returns / portfolio_cum_returns.cummax() - 1)\n",
        "    fig1.add_trace(\n",
        "        go.Scatter(x=drawdowns.index, y=drawdowns,\n",
        "                  name='Portfolio Drawdowns', line=dict(color='red')),\n",
        "        row=2, col=1\n",
        "    )\n",
        "\n",
        "    fig1.update_layout(height=800, title='Portfolio Performance Analysis')\n",
        "    fig1.update_yaxes(type=\"log\", row=1, col=1)\n",
        "\n",
        "    # Create monthly returns matrix for heatmap\n",
        "    monthly_matrix = calculate_monthly_matrix(monthly_returns)\n",
        "\n",
        "    # Create yearly comparison table\n",
        "    yearly_returns = monthly_returns.groupby(monthly_returns.index.year).apply(\n",
        "        lambda x: (1 + x).prod() - 1\n",
        "    )\n",
        "\n",
        "    yearly_comparison = pd.DataFrame({\n",
        "        'Portfolio': yearly_returns\n",
        "    })\n",
        "\n",
        "    for ticker, returns in benchmark_returns.items():\n",
        "        # Ensure benchmark returns are aligned for yearly comparison\n",
        "        aligned_returns = returns.reindex(monthly_returns.index).fillna(0)\n",
        "        yearly_comparison[ticker] = aligned_returns.groupby(aligned_returns.index.year).apply(\n",
        "            lambda x: (1 + x).prod() - 1\n",
        "        )\n",
        "\n",
        "\n",
        "    # Create heatmap figure\n",
        "    fig2 = plt.figure(figsize=(15, 8))\n",
        "    sns.heatmap(monthly_matrix,\n",
        "                cmap='RdYlGn',\n",
        "                center=0,\n",
        "                annot=True,\n",
        "                fmt='.2%')\n",
        "    plt.title('Monthly Returns Heatmap')\n",
        "\n",
        "    # Calculate yearly statistics\n",
        "    yearly_stats = pd.DataFrame(index=yearly_returns.index)\n",
        "\n",
        "    for year in yearly_returns.index:\n",
        "        year_returns = monthly_returns[monthly_returns.index.year == year]\n",
        "\n",
        "        # Basic statistics\n",
        "        yearly_stats.loc[year, 'Return'] = yearly_returns[year]\n",
        "        yearly_stats.loc[year, 'Volatility'] = year_returns.std() * np.sqrt(12)\n",
        "        yearly_stats.loc[year, 'Sharpe'] = (yearly_returns[year] - 0.02) / (year_returns.std() * np.sqrt(12))\n",
        "\n",
        "        # Sortino Ratio\n",
        "        downside_returns = year_returns[year_returns < 0]\n",
        "        if len(downside_returns) > 0:\n",
        "            yearly_stats.loc[year, 'Sortino'] = (yearly_returns[year] - 0.02) / (downside_returns.std() * np.sqrt(12))\n",
        "        else:\n",
        "            yearly_stats.loc[year, 'Sortino'] = np.nan\n",
        "\n",
        "        # Maximum Drawdown\n",
        "        cum_returns = (1 + year_returns).cumprod()\n",
        "        yearly_stats.loc[year, 'Max Drawdown'] = (cum_returns / cum_returns.cummax() - 1).min()\n",
        "\n",
        "    return {\n",
        "        'performance_plot': fig1,\n",
        "        'heatmap': fig2,\n",
        "        'yearly_comparison': yearly_comparison,\n",
        "        'yearly_stats': yearly_stats,\n",
        "        'monthly_returns': monthly_returns, # Return monthly returns\n",
        "        'benchmark_monthly_returns': benchmark_returns # Return benchmark monthly returns\n",
        "    }\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Read your data\n",
        "    returns_df = pd.read_csv('stock_returns_detailed.csv')\n",
        "    returns_df['Date'] = pd.to_datetime(returns_df['Date'])\n",
        "\n",
        "    print(\"Creating performance charts...\")\n",
        "    analysis_results = create_performance_charts(returns_df)\n",
        "\n",
        "    # Display results\n",
        "    print(\"\\nYearly Performance Comparison (%):\")\n",
        "    print(analysis_results['yearly_comparison'].round(4) * 100)\n",
        "\n",
        "    print(\"\\nYearly Statistics:\")\n",
        "    print(analysis_results['yearly_stats'].round(4))\n",
        "\n",
        "    # Save results\n",
        "    analysis_results['yearly_comparison'].to_csv('yearly_performance_comparison.csv')\n",
        "    analysis_results['yearly_stats'].to_csv('yearly_statistics.csv')\n",
        "\n",
        "    # Show plots\n",
        "    analysis_results['performance_plot'].show()\n",
        "    plt.show()  # Show the heatmap\n",
        "\n",
        "    # Additional analytics\n",
        "    monthly_returns = analysis_results['monthly_returns']\n",
        "\n",
        "    print(\"\\nPortfolio Statistics:\")\n",
        "    print(f\"Total Return: {(((1 + monthly_returns).prod() - 1) * 100):.2f}%\")\n",
        "    print(f\"Annual Return: {(((1 + monthly_returns).prod() ** (12/len(monthly_returns)) - 1) * 100):.2f}%\")\n",
        "    print(f\"Monthly Volatility: {(monthly_returns.std() * 100):.2f}%\")\n",
        "    print(f\"Annual Volatility: {(monthly_returns.std() * np.sqrt(12) * 100):.2f}%\")\n",
        "    print(f\"Sharpe Ratio: {((monthly_returns.mean() - 0.02/12) / (monthly_returns.std()) * np.sqrt(12)):.2f}\")\n",
        "    print(f\"Max Drawdown: {(((1 + monthly_returns).cumprod() / (1 + monthly_returns).cumprod().cummax() - 1).min() * 100):.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ab90ec20"
      },
      "outputs": [],
      "source": [
        "import plotly.express as px\n",
        "import pandas as pd\n",
        "\n",
        "# Get monthly portfolio returns (already calculated)\n",
        "portfolio_monthly_returns = monthly_returns * 100 # Convert to percentage\n",
        "\n",
        "# Get benchmark monthly returns (already downloaded in analysis_results)\n",
        "benchmark_monthly_returns = {}\n",
        "for ticker, returns in analysis_results['benchmark_returns'].items():\n",
        "    # Align benchmark index to the same frequency as portfolio monthly returns\n",
        "    # and convert to percentage\n",
        "    benchmark_monthly_returns[ticker] = returns.resample('M').last().reindex(portfolio_monthly_returns.index).fillna(0) * 100\n",
        "\n",
        "\n",
        "# Combine portfolio and benchmark monthly returns into a single DataFrame\n",
        "all_monthly_returns = pd.DataFrame({'Portfolio': portfolio_monthly_returns})\n",
        "for ticker, returns in benchmark_monthly_returns.items():\n",
        "    all_monthly_returns[ticker] = returns\n",
        "\n",
        "# Melt the DataFrame for Plotly Express\n",
        "melted_monthly_returns = all_monthly_returns.reset_index().melt(\n",
        "    id_vars='Date', var_name='Asset', value_name='Monthly Return (%)'\n",
        ")\n",
        "\n",
        "# Create the line plot for monthly changes\n",
        "fig = px.line(melted_monthly_returns, x='Date', y='Monthly Return (%)', color='Asset',\n",
        "              title='Month-to-Month Performance Comparison')\n",
        "fig.update_layout(xaxis_title='Date', yaxis_title='Monthly Return (%)')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "SaYAoPs6Q1cX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5abb762e"
      },
      "outputs": [],
      "source": [
        "import plotly.express as px\n",
        "import pandas as pd\n",
        "\n",
        "# Get monthly portfolio and benchmark returns\n",
        "portfolio_monthly_returns = analysis_results['monthly_returns']\n",
        "benchmark_monthly_returns = analysis_results['benchmark_monthly_returns']\n",
        "\n",
        "# Combine all monthly returns into a single DataFrame\n",
        "all_monthly_returns = pd.DataFrame({'Portfolio': portfolio_monthly_returns})\n",
        "for ticker, returns in benchmark_monthly_returns.items():\n",
        "    # Ensure benchmark returns are aligned to the same index\n",
        "    all_monthly_returns[ticker] = returns.reindex(portfolio_monthly_returns.index).fillna(0)\n",
        "\n",
        "\n",
        "# Calculate cumulative returns\n",
        "cumulative_returns = (1 + all_monthly_returns).cumprod() - 1\n",
        "\n",
        "# Convert to percentage and melt for Plotly Express\n",
        "melted_cumulative_returns = cumulative_returns.reset_index().melt(\n",
        "    id_vars='Date', var_name='Asset', value_name='Cumulative Return (%)'\n",
        ")\n",
        "\n",
        "# Create the cumulative line plot\n",
        "fig = px.line(melted_cumulative_returns, x='Date', y='Cumulative Return (%)', color='Asset',\n",
        "              title='Cumulative Performance Comparison')\n",
        "fig.update_layout(xaxis_title='Date', yaxis_title='Cumulative Return (%)')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "KS7HOw8LROd5"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}